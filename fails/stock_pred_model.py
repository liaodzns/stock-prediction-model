# -*- coding: utf-8 -*-
"""stock-pred-model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wcHXqd28AC0aITHEpMogTXNvob96ofH5
"""

import yfinance as yf
import tensorflow as tf
import pandas as pd
import ta
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from keras._tf_keras.keras.models import Sequential
from keras._tf_keras.keras.layers import LSTM, Dense, Dropout, Input
from keras._tf_keras.keras.regularizers import L2

stock_chosen = yf.Ticker("AAPL")

stock_data = stock_chosen.history(start='2010-01-01', end='2024-09-01', interval="1d")

stock_data['MA_20'] = ta.trend.sma_indicator(stock_data['Close'], window=20)
stock_data['MA_50'] = ta.trend.sma_indicator(stock_data['Close'], window=50)

stock_data['RSI'] = ta.momentum.rsi(stock_data['Close'], window=14)

macd = ta.trend.MACD(stock_data['Close'])
stock_data['MACD'] = macd.macd()
stock_data['MACD_Signal'] = macd.macd_signal()
stock_data['MACD_Diff'] = macd.macd_diff()

bollinger = ta.volatility.BollingerBands(stock_data['Close'], window=20, window_dev=2)
stock_data['Bollinger_High'] = bollinger.bollinger_hband()
stock_data['Bollinger_Low'] = bollinger.bollinger_lband()

stock_data.dropna(inplace=True)

sp500 = yf.download('^GSPC', start='2010-01-01', end='2024-09-01', progress=False)
sp500 = sp500['Close'].rename('S&P500_Close')

stock_data.index = stock_data.index.tz_localize(None)
sp500.index = sp500.index.tz_localize(None)

print(stock_data.index.tz)
print(sp500.index.tz)

stock_data = stock_data.join(sp500, how='inner')

print(stock_data.columns)

# relevant features
features = ['Open', 'Close', 'Volume', 'S&P500_Close']
stock_data = stock_data[features].dropna()

stock_data['Target'] = stock_data['Close'].shift(-1)
stock_data.dropna(inplace=True)

X = stock_data[features]
y = stock_data['Target']

X_train_full, X_test, y_train_full, y_test = train_test_split(
    X, y, test_size=0.15, shuffle=False)  # Shuffle=False for time series

X_train, X_val, y_train, y_val = train_test_split(
    X_train_full, y_train_full, test_size=0.1765, shuffle=False)

scaler = MinMaxScaler(feature_range=(0, 1))

X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

y_train_scaled = scaler.transform(y_train.values.reshape(-1, 1))
y_val_scaled = scaler.transform(y_val.values.reshape(-1, 1))
y_test_scaled = scaler.transform(y_test.values.reshape(-1, 1))

"""LSTM Neural Network:"""

window_size = 120

def create_sequences(X, y, window_size):
    Xs, ys = [], []
    for i in range(len(X) - window_size):
        Xs.append(X[i:i+window_size])
        ys.append(y[i+window_size])
    return np.array(Xs), np.array(ys)

X_train_lstm, y_train_lstm = create_sequences(X_train_scaled, y_train_scaled, window_size)
X_val_lstm, y_val_lstm = create_sequences(X_val_scaled, y_val_scaled, window_size)
X_test_lstm, y_test_lstm = create_sequences(X_test_scaled, y_test_scaled, window_size)

model = Sequential([
    Input(shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),
    LSTM(128, return_sequences=True, kernel_regularizer=L2(0.001)),
    Dropout(0.2),
    LSTM(64, return_sequences=False, kernel_regularizer=L2(0.001)),
    Dropout(0.2),
    Dense(32, activation='relu', kernel_regularizer=L2(0.001)),
    Dense(1)
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), 
              loss='mean_squared_error')

early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)

history = model.fit(
    X_train_lstm, y_train_lstm,
    epochs=100,
    batch_size=32,
    validation_data=(X_val_lstm, y_val_lstm),
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

# predict
y_pred_lstm = model.predict(X_test_lstm)
y_pred_lstm = y_pred_lstm.flatten()

# Inverse transform the scaled data
y_test_inv = scaler.inverse_transform(y_test_lstm.reshape(-1, 1)).flatten()
y_pred_inv = scaler.inverse_transform(y_pred_lstm.reshape(-1, 1)).flatten()

# Calculate MSE and RMSE
mse_lstm = mean_squared_error(y_test_inv, y_pred_inv)
rmse = np.sqrt(mse_lstm)

average_actual_price = np.mean(y_test_lstm)
rmse_percentage_error = (rmse / average_actual_price) * 100

print(f"MSE: {mse_lstm:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"RMSE Percentage Error: {rmse_percentage_error:.2f}%")


plt.figure(figsize=(14, 7))

train_size = len(y_train_lstm)
test_size = len(y_test_lstm)

plt.plot(range(train_size), y_train_lstm, label='Actual Training Prices', color='blue')
plt.plot(range(train_size, train_size + test_size), y_test_lstm, label='Actual Test Prices', color='cyan')
plt.plot(range(train_size, train_size + test_size), y_pred_lstm, label='Predicted Test Prices', color='green')

plt.title('LSTM: Actual vs Predicted Prices (Train and Predict)')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()