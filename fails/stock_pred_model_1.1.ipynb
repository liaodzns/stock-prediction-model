{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from keras._tf_keras.keras.models import Sequential\n",
    "from keras._tf_keras.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras._tf_keras.keras.regularizers import L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(stock):\n",
    "    stock_chosen = yf.Ticker(f\"{stock}\")\n",
    "    stock_data = stock_chosen.history(start='2010-01-01', end='2024-09-01', interval=\"1d\")\n",
    "    \n",
    "    stock_data.dropna(inplace=True)\n",
    "    sp500_data = yf.download(\"^GSPC\", start='2010-01-01', end='2024-09-01', interval=\"1d\")\n",
    "    sp500_data = sp500_data['Close'].rename('S&P500_Close')\n",
    "    stock_data.index = stock_data.index.tz_localize(None)\n",
    "    sp500_data.index = sp500_data.index.tz_localize(None)\n",
    "    stock_data = stock_data.join(sp500_data, how='inner')\n",
    "    \n",
    "    print(stock_data.columns)\n",
    "    features = ['Open', 'Close', 'Volume', 'S&P500_Close']\n",
    "    stock_data = stock_data[features].dropna()\n",
    "    \n",
    "    stock_data['Target'] = stock_data['Close'].shift(-1)\n",
    "    stock_data.dropna(inplace=True)\n",
    "    \n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing a stock to train our model on: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits',\n",
      "       'S&P500_Close'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['Open', 'Close', 'Volume', 'S&P500_Close']\n",
    "stock_data = format_data(\"GOOG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stock_data[features]  \n",
    "Y = stock_data['Target']  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(stock_data, features, test_size=0.2, val_size=0.2):\n",
    "    X = stock_data[features]\n",
    "    Y = stock_data['Target']\n",
    "    \n",
    "    # Separate test set\n",
    "    X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Separate validation set from the remaining data\n",
    "    val_ratio = val_size / (1 - test_size)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=val_ratio, random_state=42)\n",
    "    \n",
    "    return X_train, X_val, X_test, Y_train, Y_val, Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, Y_train, Y_val, Y_test = create_train_test(stock_data, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2213, 4) (2213,)\n",
      "(738, 4) (738,)\n",
      "(738, 4) (738,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_val.shape, Y_val.shape)\n",
    "print(X_test.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2021-09-23', '2021-09-24', '2021-09-27', '2021-09-28',\n",
      "               '2021-09-29', '2021-09-30', '2021-10-01', '2021-10-04',\n",
      "               '2021-10-05', '2021-10-06',\n",
      "               ...\n",
      "               '2024-08-16', '2024-08-19', '2024-08-20', '2024-08-21',\n",
      "               '2024-08-22', '2024-08-23', '2024-08-26', '2024-08-27',\n",
      "               '2024-08-28', '2024-08-29'],\n",
      "              dtype='datetime64[ns]', name='Date', length=738, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(stock_data.index[-len(Y_test):])  # Ensure this matches with test set plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we implement a MinMaxScaler to scale our data and ensure that all values are between 0 and 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createScalar(sequence_length=60):\n",
    "    # Initialize scalers\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_Y = MinMaxScaler()\n",
    "    \n",
    "    # Scale X data\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_val_scaled = scaler_X.transform(X_val)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    \n",
    "    # Scale Y values in 2D\n",
    "    Y_train_scaled = scaler_Y.fit_transform(Y_train.values.reshape(-1, 1))\n",
    "    Y_val_scaled = scaler_Y.transform(Y_val.values.reshape(-1, 1))\n",
    "    Y_test_scaled = scaler_Y.transform(Y_test.values.reshape(-1, 1))\n",
    "    \n",
    "    # Create sequences for LSTM\n",
    "    X_train_seq, Y_train_seq = create_sequences(X_train_scaled, Y_train_scaled, sequence_length)\n",
    "    X_val_seq, Y_val_seq = create_sequences(X_val_scaled, Y_val_scaled, sequence_length)\n",
    "    X_test_seq, Y_test_seq = create_sequences(X_test_scaled, Y_test_scaled, sequence_length)\n",
    "    \n",
    "    return X_train_seq, X_val_seq, X_test_seq, Y_train_seq, Y_val_seq, Y_test_seq, scaler_Y\n",
    "\n",
    "def create_sequences(X_data, Y_data, sequence_length=60):\n",
    "    Xs, Ys = [], []\n",
    "    for i in range(len(X_data) - sequence_length):\n",
    "        Xs.append(X_data[i:(i + sequence_length)])\n",
    "        Ys.append(Y_data[i + sequence_length])\n",
    "    return np.array(Xs), np.array(Ys)\n",
    "\n",
    "\n",
    "X_train_seq, X_val_seq, X_test_seq, Y_train_seq, Y_val_seq, Y_test_seq, scaler_Y = createScalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2153, 60, 4)\n",
      "(2153, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_seq.shape)  # Expected shape: (samples, sequence_length, features)\n",
    "print(Y_train_seq.shape)  # Expected shape: (samples, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile the model, train the model, and evaluate the model:\n",
    "\n",
    "input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])\n",
    "model = createModel(input_shape)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_seq, Y_train_seq,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_seq, Y_val_seq),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_loss = model.evaluate(X_train_seq, Y_train_seq    , verbose=0)\n",
    "val_loss = model.evaluate(X_val_seq, Y_val_seq, verbose=0)\n",
    "test_loss = model.evaluate(X_test_seq, Y_test_seq, verbose=0)\n",
    "\n",
    "print(f\"Train Loss: {train_loss}\")\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Make predictions\n",
    "train_predictions = model.predict(X_train_seq)\n",
    "val_predictions = model.predict(X_val_seq)\n",
    "test_predictions = model.predict(X_test_seq)\n",
    "\n",
    "# Calculate RMSE percentage error\n",
    "def rmse_percentage_error(y_true, y_pred):\n",
    "    y_true = scaler_Y.inverse_transform(y_true)\n",
    "    y_pred = scaler_Y.inverse_transform(y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mean_price = np.mean(y_true)\n",
    "    return (rmse / mean_price) * 100\n",
    "\n",
    "train_rmse_pct = rmse_percentage_error(Y_train_seq, train_predictions)\n",
    "val_rmse_pct = rmse_percentage_error(Y_val_seq, val_predictions)\n",
    "test_rmse_pct = rmse_percentage_error(Y_test_seq, test_predictions)\n",
    "\n",
    "print(f\"Train RMSE Percentage Error: {train_rmse_pct:.2f}%\")\n",
    "print(f\"Validation RMSE Percentage Error: {val_rmse_pct:.2f}%\")\n",
    "print(f\"Test RMSE Percentage Error: {test_rmse_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "def plot_predictions(y_true, y_pred, title):\n",
    "    y_true = scaler_Y.inverse_transform(y_true).flatten()\n",
    "    y_pred = scaler_Y.inverse_transform(y_pred).flatten()\n",
    "    \n",
    "    # Get the corresponding dates for the test set\n",
    "    test_dates = stock_data.index[-len(y_true):]\n",
    "    \n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.plot(test_dates, y_true, label='Actual', linewidth=2)\n",
    "    plt.plot(test_dates, y_pred, label='Predicted', linewidth=2)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Stock Price', fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add text with min and max values\n",
    "    plt.text(0.02, 0.98, f'Actual range: {y_true.min():.2f} - {y_true.max():.2f}', \n",
    "             transform=plt.gca().transAxes, verticalalignment='top')\n",
    "    plt.text(0.02, 0.94, f'Predicted range: {y_pred.min():.2f} - {y_pred.max():.2f}', \n",
    "             transform=plt.gca().transAxes, verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(Y_test_seq, test_predictions, 'Test Set: Actual vs Predicted')\n",
    "\n",
    "# Plot prediction error distribution\n",
    "def plot_error_distribution(y_true, y_pred, title):\n",
    "    y_true = scaler_Y.inverse_transform(y_true)\n",
    "    y_pred = scaler_Y.inverse_transform(y_pred)\n",
    "    errors = y_true - y_pred\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.histplot(errors, kde=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Prediction Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "plot_error_distribution(Y_test_seq, test_predictions, 'Test Set: Prediction Error Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock_prediction(stock_data, y_true, y_pred, scaler_y, sequence_length):\n",
    "    # Get the closing prices for the entire stock data\n",
    "    closing_prices = stock_data['Close'].values.reshape(-1, 1)\n",
    "\n",
    "    # Calculate the split point (80% of the data) to separate historical data from predictions\n",
    "    split_point = int(len(closing_prices) * 0.8)\n",
    "\n",
    "    # Create a time index from the stock data index\n",
    "    time_index = stock_data.index\n",
    "\n",
    "    # Inverse transform the predictions and actual values\n",
    "    y_true_inv = scaler_y.inverse_transform(y_true)\n",
    "    y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "\n",
    "    # The predicted data starts after the sequence length, so adjust the time index accordingly\n",
    "    test_time_index = time_index[-len(y_true):]  # Time index for the test set\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # Plot the historical data (before the test set)\n",
    "    plt.plot(time_index[:split_point], closing_prices[:split_point], label='Historical Data', color='blue')\n",
    "\n",
    "    # Plot the actual values (from the test set)\n",
    "    plt.plot(test_time_index, y_true_inv, label='Actual', color='green')\n",
    "\n",
    "    # Plot the predicted values\n",
    "    plt.plot(test_time_index, y_pred_inv, label='Predicted', color='red')\n",
    "\n",
    "    # Add vertical line to separate historical and prediction data\n",
    "    plt.axvline(x=time_index[split_point], color='gray', linestyle='--')\n",
    "\n",
    "    plt.title('Stock Price: Historical Data, Actual vs Predicted')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to create the plot (use the sequence-based test predictions and actual values)\n",
    "plot_stock_prediction(stock_data, Y_test_seq, test_predictions, scaler_Y, sequence_length)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
